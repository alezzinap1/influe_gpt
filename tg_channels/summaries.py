# telegram_summaries.py

from dataclasses import dataclass
from typing import List, Dict, Tuple
from pathlib import Path

import pandas as pd
import re
import asyncio
import threading
import time
import logging

from config_telegram import RAW_DIR
from rag.llm_backends import DeepSeekBackend, GeminiBackend, OpenAIBackend
from settings import SUMMARY_BACKEND
from tg_channels.prompts import (
    YEAR_SUMMARY_PROMPT,
    QUARTER_SUMMARY_PROMPT,
    AUTHOR_QUARTER_PROMPT,
    AUTHOR_YEAR_PROMPT,
    AUTHOR_REPORT_PROMPT,
    AUTHOR_REPORT_IDENTITY_STYLE_PROMPT,
    AUTHOR_REPORT_EVOLUTION_STRENGTHS_PROMPT,
    YEAR_EVOLUTION_PARAGRAPH_PROMPT,
)

logger = logging.getLogger(__name__)

from settings import LLM_SEMAPHORE_LIMIT

# –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ 8 –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö LLM-–∑–∞–ø—Ä–æ—Å–∞ (–æ–±—â–∏–π –ª–∏–º–∏—Ç –Ω–∞ –≤—Å–µ –∑–∞–¥–∞—á–∏)
_LLM_SEMAPHORE_LIMIT = LLM_SEMAPHORE_LIMIT
# –•—Ä–∞–Ω–∏–ª–∏—â–µ —Å–µ–º–∞—Ñ–æ—Ä–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ event loop (–ø–æ id loop)
_LLM_SEMAPHORES = {}
# –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∞ –¥–ª—è thread-safe –¥–æ—Å—Ç—É–ø–∞ –∫ —Å–ª–æ–≤–∞—Ä—é —Å–µ–º–∞—Ñ–æ—Ä–æ–≤
_semaphore_lock = threading.Lock()

def _get_semaphore():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–µ–º–∞—Ñ–æ—Ä –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ event loop (thread-safe)."""
    # –í async –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å running loop
    loop = asyncio.get_running_loop()
    loop_id = id(loop)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—É—Ç–∏
    if loop_id in _LLM_SEMAPHORES:
        return _LLM_SEMAPHORES[loop_id]
    
    # –°–æ–∑–¥–∞–µ–º —Å–µ–º–∞—Ñ–æ—Ä —Å –±–ª–æ–∫–∏—Ä–æ–≤–∫–æ–π –¥–ª—è thread-safety
    with _semaphore_lock:
        # Double-check –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
        if loop_id not in _LLM_SEMAPHORES:
            _LLM_SEMAPHORES[loop_id] = asyncio.Semaphore(_LLM_SEMAPHORE_LIMIT)
    
    return _LLM_SEMAPHORES[loop_id]


def _get_summary_llm():
    """
    –ü–æ–ª—É—á–∏—Ç—å LLM –±—ç–∫–µ–Ω–¥ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–∞–º–º–∞—Ä–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ SUMMARY_BACKEND.
    
    Returns:
        LLMBackend: –≠–∫–∑–µ–º–ø–ª—è—Ä –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –±—ç–∫–µ–Ω–¥–∞ (DeepSeekBackend, GeminiBackend –∏–ª–∏ OpenAIBackend)
    """
    backend = SUMMARY_BACKEND.lower()
    
    if backend == "gemini":
        return GeminiBackend(model="gemini-3-flash-preview")
    elif backend == "openai":
        return OpenAIBackend()
    elif backend == "deepseek":
        return DeepSeekBackend(model="deepseek-chat")
    else:
        logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –±—ç–∫–µ–Ω–¥ —Å–∞–º–º–∞—Ä–∏: {backend}, –∏—Å–ø–æ–ª—å–∑—É–µ–º DeepSeek –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é")
        return DeepSeekBackend(model="deepseek-chat")

SHORT_TEXT_MIN_LEN = 10  # –∂—ë—Å—Ç–∫–∏–π –ø–æ—Ä–æ–≥ –¥–ª–∏–Ω—ã

URL_RE = re.compile(r"https?://\S+")
EMOJI_RE = re.compile(r"[\u2600-\u27BF\u1F300-\u1F6FF]+")


async def _run_in_thread(func, *args, **kwargs):
    """–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ –ø–æ–¥ —Å–µ–º–∞—Ñ–æ—Ä–æ–º."""
    semaphore = _get_semaphore()
    async with semaphore:
        loop = asyncio.get_event_loop()
        return await loop.run_in_executor(None, lambda: func(*args, **kwargs))


def _looks_like_noise(text: str) -> bool:
    t = text.strip().lower()

    if not t:
        return True

    if len(t) <= 3 and not re.search(r"[a-z–∞-—è0-9]", t):
        return True

    noise_tokens = {
        "ok",
        "–æ–∫",
        "++",
        "+",
        "–¥–∞",
        "–Ω–µ—Ç",
        "–∞–≥–∞",
        "—Ç–µ—Å—Ç",
        "test",
        "upd",
        "update",
    }
    if t in noise_tokens:
        return True

    if URL_RE.fullmatch(t):
        return True

    if not re.search(r"[a-z–∞-—è0-9]", t):
        return True

    return False


def clean_raw_messages(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()

    for col in ("is_service", "service", "action"):
        if col in df.columns:
            df = df[
                ~df[col]
                .astype(str)
                .str.contains("True|joined|left|pinned", case=False, na=False)
            ]

    df["text"] = df.get("text", "").fillna("").astype(str)

    df = df[df["text"].str.len() >= SHORT_TEXT_MIN_LEN]

    df = df[~df["text"].apply(_looks_like_noise)]

    df = df.drop_duplicates(subset=["text"])

    def _too_link_heavy(t: str) -> bool:
        links = len(URL_RE.findall(t))
        return links >= 2 and len(t) < 3 * 80

    df = df[~df["text"].apply(_too_link_heavy)]

    return df


@dataclass
class QuarterSummary:
    channel: str
    year: int
    quarter: int
    summary_text: str


@dataclass
class PeriodSummary:
    channel: str
    year: int
    summary_text: str


def _load_raw_channel_df(channel: str) -> pd.DataFrame:
    safe = channel.lstrip("@").replace("/", "_")
    path = RAW_DIR / f"{safe}.parquet"
    if not path.exists():
        raise FileNotFoundError(f"raw parquet not found: {path}")
    df = pd.read_parquet(path)
    df = clean_raw_messages(df)
    return df


def _group_messages_by_year(df: pd.DataFrame) -> Dict[int, pd.DataFrame]:
    df = df.copy()
    df["year"] = df["date"].dt.year
    groups: Dict[int, pd.DataFrame] = {}
    for year, g in df.groupby("year"):
        groups[int(year)] = g.sort_values("date")
    return groups


def _group_messages_by_year_quarter(
    df: pd.DataFrame,
) -> Dict[Tuple[int, int], pd.DataFrame]:
    df = df.copy()
    df["year"] = df["date"].dt.year
    df["quarter"] = ((df["date"].dt.month - 1) // 3 + 1).astype(int)
    groups: Dict[Tuple[int, int], pd.DataFrame] = {}
    for (year, quarter), g in df.groupby(["year", "quarter"]):
        groups[(int(year), int(quarter))] = g.sort_values("date")
    return groups


def _smart_select_messages(texts: list[str], max_chars: int = 9600) -> list[str]:
    """
    –£–ª—É—á—à–µ–Ω–Ω–∞—è —É–º–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–∞–º–º–∞—Ä–∏.
    
    –°—Ç—Ä–∞—Ç–µ–≥–∏—è:
    1. –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –≤—Å–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ (–Ω–∞—á–∞–ª–æ, —Å–µ—Ä–µ–¥–∏–Ω–∞, –∫–æ–Ω–µ—Ü)
    2. –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥: –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è + —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞
    3. –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —Ä–∞–∑–º–µ—Ä –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥–æ–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
    4. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ª–∏–º–∏—Ç–∞ (–¥–æ 95-98%)
    5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–≥–æ –ø–æ—Ä—è–¥–∫–∞
    
    Args:
        texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º –ø–æ—Ä—è–¥–∫–µ
        max_chars: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 9600, +20% –æ—Ç 8000)
    
    Returns:
        –û—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –ø–æ—Ä—è–¥–∫–µ
    """
    if not texts:
        return []
    
    total_chars = sum(len(t) for t in texts)
    if total_chars <= max_chars:
        return texts
    
    n = len(texts)
    if n == 0:
        return []
    
    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (1/4 –æ—Ç –ª–∏–º–∏—Ç–∞)
    # –ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —Å–∏—Ç—É–∞—Ü–∏—é, –∫–æ–≥–¥–∞ –æ–¥–Ω–æ –æ—á–µ–Ω—å –¥–ª–∏–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞–Ω–∏–º–∞–µ—Ç –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –ª–∏–º–∏—Ç–∞
    max_single_msg = max_chars // 4  # ~2400 —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è –ª–∏–º–∏—Ç–∞ 9600
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ 3 —á–∞—Å—Ç–∏ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ–∫—Ä—ã—Ç–∏—è –ø–µ—Ä–∏–æ–¥–∞
    part_size = max(1, n // 3)
    parts = [
        (0, texts[:part_size]),  # –ù–∞—á–∞–ª–æ –ø–µ—Ä–∏–æ–¥–∞
        (1, texts[part_size:2*part_size]),  # –°–µ—Ä–µ–¥–∏–Ω–∞ –ø–µ—Ä–∏–æ–¥–∞
        (2, texts[2*part_size:])  # –ö–æ–Ω–µ—Ü –ø–µ—Ä–∏–æ–¥–∞
    ]
    
    # –ë—é–¥–∂–µ—Ç –Ω–∞ –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å: 30% –Ω–∞ –¥–ª–∏–Ω–Ω—ã–µ, 20% –Ω–∞ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–µ = 50% –Ω–∞ —á–∞—Å—Ç—å
    # –û—Å—Ç–∞–ª—å–Ω—ã–µ 50% –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è
    budget_per_part_long = int(max_chars * 0.30)  # 30% –Ω–∞ –¥–ª–∏–Ω–Ω—ã–µ –∏–∑ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏
    budget_per_part_uniform = int(max_chars * 0.20)  # 20% –Ω–∞ —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–µ –∏–∑ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏
    
    selected_indices = set()
    selected_with_indices = []  # (original_index, text)
    chars_used = 0
    
    # –§–∞–∑–∞ 1: –í—ã–±–æ—Ä–∫–∞ –∏–∑ –∫–∞–∂–¥–æ–π —á–∞—Å—Ç–∏ (–¥–ª–∏–Ω–Ω—ã–µ + —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω—ã–µ)
    for part_idx, part_texts in parts:
        if not part_texts:
            continue
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏ –¥–ª—è —ç—Ç–æ–π —á–∞—Å—Ç–∏
        if part_idx == 0:
            start_idx = 0
        elif part_idx == 1:
            start_idx = part_size
        else:  # part_idx == 2
            start_idx = 2 * part_size
        part_with_indices = [(start_idx + i, text) for i, text in enumerate(part_texts)]
        
        # 1.1. –í—ã–±–∏—Ä–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ —ç—Ç–æ–π —á–∞—Å—Ç–∏ (–Ω–æ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –Ω–∞ —Ä–∞–∑–º–µ—Ä)
        part_sorted_by_length = sorted(part_with_indices, key=lambda x: len(x[1]), reverse=True)
        
        part_long_chars = 0
        for orig_idx, msg in part_sorted_by_length:
            if orig_idx in selected_indices:
                continue
            
            msg_len = len(msg)
            # –û–±—Ä–µ–∑–∞–µ–º —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            if msg_len > max_single_msg:
                msg = msg[:max_single_msg]
                msg_len = max_single_msg
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–ª–µ–∑–∞–µ—Ç –ª–∏ –≤ –æ–±—â–∏–π –ª–∏–º–∏—Ç –∏ –±—é–¥–∂–µ—Ç —á–∞—Å—Ç–∏
            if (chars_used + msg_len <= max_chars * 0.95 and  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ 95% –ª–∏–º–∏—Ç–∞
                part_long_chars + msg_len <= budget_per_part_long):
                selected_with_indices.append((orig_idx, msg))
                selected_indices.add(orig_idx)
                chars_used += msg_len
                part_long_chars += msg_len
        
        # 1.2. –†–∞–≤–Ω–æ–º–µ—Ä–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞ –∏–∑ —ç—Ç–æ–π —á–∞—Å—Ç–∏ (–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –ø–æ–∫—Ä—ã—Ç–∏–µ)
        part_uniform_chars = 0
        remaining_in_part = [(idx, text) for idx, text in part_with_indices 
                            if idx not in selected_indices]
        
        if remaining_in_part:
            # –ë–µ—Ä–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            step = max(1, len(remaining_in_part) // max(1, (budget_per_part_uniform // 150)))
            for i in range(0, len(remaining_in_part), step):
                orig_idx, msg = remaining_in_part[i]
                msg_len = len(msg)
                
                if (chars_used + msg_len <= max_chars * 0.95 and
                    part_uniform_chars + msg_len <= budget_per_part_uniform):
                    selected_with_indices.append((orig_idx, msg))
                    selected_indices.add(orig_idx)
                    chars_used += msg_len
                    part_uniform_chars += msg_len
                else:
                    # –ü—Ä–æ–±—É–µ–º –¥–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω–æ–µ, –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–æ—Å—å –º–µ—Å—Ç–æ
                    remaining = min(max_chars * 0.95 - chars_used, 
                                  budget_per_part_uniform - part_uniform_chars)
                    if remaining > 100:  # –ú–∏–Ω–∏–º—É–º 100 —Å–∏–º–≤–æ–ª–æ–≤
                        trimmed_msg = msg[:int(remaining)]
                        selected_with_indices.append((orig_idx, trimmed_msg))
                        selected_indices.add(orig_idx)
                        chars_used += len(trimmed_msg)
                        part_uniform_chars += len(trimmed_msg)
                    break
    
    # –§–∞–∑–∞ 2: –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –º–µ—Å—Ç–∞ –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è 5-10% –ª–∏–º–∏—Ç–∞ –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
    remaining_budget = int(max_chars * 0.98) - chars_used  # –°—Ç—Ä–µ–º–∏–º—Å—è –∫ 98% –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    
    if remaining_budget > 200:  # –ï—Å–ª–∏ –æ—Å—Ç–∞–ª–æ—Å—å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –º–µ—Å—Ç–∞
        all_remaining = [(i, text) for i, text in enumerate(texts) 
                        if i not in selected_indices]
        
        if all_remaining:
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–ª–∏–Ω–µ (—Å–Ω–∞—á–∞–ª–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ, –ø–æ—Ç–æ–º —Å—Ä–µ–¥–Ω–∏–µ)
            # –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª—å—à–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
            all_remaining_sorted = sorted(all_remaining, key=lambda x: len(x[1]))
            
            for orig_idx, msg in all_remaining_sorted:
                msg_len = len(msg)
                if chars_used + msg_len <= max_chars * 0.98:
                    selected_with_indices.append((orig_idx, msg))
                    selected_indices.add(orig_idx)
                    chars_used += msg_len
                else:
                    # –ü—Ä–æ–±—É–µ–º –¥–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–µ–∑–∞–Ω–Ω–æ–µ
                    remaining = int(max_chars * 0.98) - chars_used
                    if remaining > 100:
                        trimmed_msg = msg[:remaining]
                        selected_with_indices.append((orig_idx, trimmed_msg))
                        chars_used += len(trimmed_msg)
                    break
    
    # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ö—Ä–æ–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—è–¥–æ–∫
    selected_with_indices.sort(key=lambda x: x[0])
    return [msg for _, msg in selected_with_indices]


def _build_year_prompt(channel: str, year: int, texts: list[str]) -> tuple[str, int, int, int]:
    """
    –°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–æ–¥–æ–≤–æ–≥–æ —Å–∞–º–º–∞—Ä–∏ —Å —É–º–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–π —Å–æ–æ–±—â–µ–Ω–∏–π.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (prompt, original_count, selected_count, context_chars)
    """
    original_count = len(texts)
    selected_texts = _smart_select_messages(texts, max_chars=9600)  # +20% –ª–∏–º–∏—Ç
    selected_count = len(selected_texts)
    joined = "\n\n".join(selected_texts)
    context_chars = len(joined)
    
    prompt = YEAR_SUMMARY_PROMPT.format(channel=channel, year=year, messages=joined)
    return prompt, original_count, selected_count, context_chars


def _build_quarter_prompt(
    channel: str, year: int, quarter: int, texts: list[str]
) -> tuple[str, int, int, int]:
    """
    –°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ–≥–æ —Å–∞–º–º–∞—Ä–∏ —Å —É–º–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–π —Å–æ–æ–±—â–µ–Ω–∏–π.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (prompt, original_count, selected_count, context_chars)
    """
    original_count = len(texts)
    selected_texts = _smart_select_messages(texts, max_chars=9600)  # +20% –ª–∏–º–∏—Ç
    selected_count = len(selected_texts)
    joined = "\n\n".join(selected_texts)
    context_chars = len(joined)
    
    prompt = QUARTER_SUMMARY_PROMPT.format(
        channel=channel, year=year, quarter=quarter, messages=joined
    )
    return prompt, original_count, selected_count, context_chars


def build_quarter_summaries(channel: str) -> list[QuarterSummary]:
    df = _load_raw_channel_df(channel)
    groups = _group_messages_by_year_quarter(df)
    llm = _get_summary_llm()

    summaries: list[QuarterSummary] = []
    total_start = time.time()
    
    logger.info(f"[SUMMARY] –ù–∞—á–∞–ª–æ —Å–æ–∑–¥–∞–Ω–∏—è –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã—Ö —Å–∞–º–º–∞—Ä–∏ –¥–ª—è {channel}")
    
    for (year, quarter), g in sorted(groups.items()):
        texts = [str(t).strip() for t in g["text"].tolist() if str(t).strip()]
        if not texts:
            continue
        
        start_time = time.time()
        prompt, orig_count, sel_count, ctx_chars = _build_quarter_prompt(channel, year, quarter, texts)
        
        logger.info(f"[SUMMARY] {channel} {year}Q{quarter}: {orig_count}‚Üí{sel_count} msg, {ctx_chars:,} chars")
        
        summary = llm.generate(prompt)
        elapsed = time.time() - start_time
        
        logger.info(f"[SUMMARY] {channel} {year}Q{quarter}: –≥–æ—Ç–æ–≤–æ –∑–∞ {elapsed:.1f}s")
        
        summaries.append(
            QuarterSummary(
                channel=channel,
                year=year,
                quarter=quarter,
                summary_text=summary,
            )
        )
    
    total_elapsed = time.time() - total_start
    logger.info(f"[SUMMARY] –í—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ {len(summaries)} –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã—Ö —Å–∞–º–º–∞—Ä–∏ –∑–∞ {total_elapsed:.1f}s")
    
    return summaries


def build_year_summaries(channel: str) -> List[PeriodSummary]:
    df = _load_raw_channel_df(channel)
    groups = _group_messages_by_year(df)
    llm = _get_summary_llm()

    summaries: List[PeriodSummary] = []
    total_start = time.time()
    
    logger.info(f"[SUMMARY] –ù–∞—á–∞–ª–æ —Å–æ–∑–¥–∞–Ω–∏—è –≥–æ–¥–æ–≤—ã—Ö —Å–∞–º–º–∞—Ä–∏ –¥–ª—è {channel}")
    
    for year, g in sorted(groups.items()):
        texts = [str(t).strip() for t in g["text"].tolist() if str(t).strip()]
        if not texts:
            continue
        
        start_time = time.time()
        prompt, orig_count, sel_count, ctx_chars = _build_year_prompt(channel, year, texts)
        
        logger.info(f"[SUMMARY] {channel} {year}: {orig_count}‚Üí{sel_count} msg, {ctx_chars:,} chars")
        
        summary = llm.generate(prompt)
        elapsed = time.time() - start_time
        
        logger.info(f"[SUMMARY] {channel} {year}: –≥–æ—Ç–æ–≤–æ –∑–∞ {elapsed:.1f}s")
        
        summaries.append(
            PeriodSummary(channel=channel, year=year, summary_text=summary)
        )
    
    total_elapsed = time.time() - total_start
    logger.info(f"[SUMMARY] –í—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ {len(summaries)} –≥–æ–¥–æ–≤—ã—Ö —Å–∞–º–º–∞—Ä–∏ –∑–∞ {total_elapsed:.1f}s")
    
    return summaries


def save_quarter_summaries_parquet(
    channel: str, summaries: list[QuarterSummary]
) -> Path:
    if not summaries:
        raise ValueError("No quarter summaries to save")

    rows = [
        {
            "channel": s.channel,
            "year": s.year,
            "quarter": s.quarter,
            "summary_text": s.summary_text,
        }
        for s in summaries
    ]
    df = pd.DataFrame(rows)
    safe = channel.lstrip("@").replace("/", "_")
    out_dir = Path("data") / "processed" / safe
    out_dir.mkdir(parents=True, exist_ok=True)
    path = out_dir / "summaries_quarter.parquet"
    df.to_parquet(path, index=False)
    print(f"üíæ saved quarter summaries to {path}")
    return path


def save_year_summaries_parquet(
    channel: str, summaries: List[PeriodSummary]
) -> Path:
    if not summaries:
        raise ValueError("No summaries to save")

    rows = [
        {"channel": s.channel, "year": s.year, "summary_text": s.summary_text}
        for s in summaries
    ]
    df = pd.DataFrame(rows)
    safe = channel.lstrip("@").replace("/", "_")
    out_dir = Path("data") / "processed" / safe
    out_dir.mkdir(parents=True, exist_ok=True)
    path = out_dir / "summaries_year.parquet"
    df.to_parquet(path, index=False)
    print(f"üíæ saved year summaries to {path}")
    return path


def load_year_summaries(channel: str) -> Dict[int, str]:
    safe = channel.lstrip("@").replace("/", "_")
    path = Path("data") / "processed" / safe / "summaries_year.parquet"
    if not path.exists():
        return {}
    df = pd.read_parquet(path)
    out: Dict[int, str] = {}
    for row in df.itertuples():
        out[int(row.year)] = str(row.summary_text)
    return out


def load_quarter_summaries(channel: str) -> Dict[Tuple[int, int], str]:
    safe = channel.lstrip("@").replace("/", "_")
    path = Path("data") / "processed" / safe / "summaries_quarter.parquet"
    if not path.exists():
        return {}
    df = pd.read_parquet(path)
    out: Dict[Tuple[int, int], str] = {}
    for row in df.itertuples():
        out[(int(row.year), int(row.quarter))] = str(row.summary_text)
    return out


def build_all_summaries_for_channel(channel: str):
    year_summ = build_year_summaries(channel)
    if year_summ:
        save_year_summaries_parquet(channel, year_summ)
    q_summ = build_quarter_summaries(channel)
    if q_summ:
        save_quarter_summaries_parquet(channel, q_summ)


# ===== –ê–í–¢–û–†–°–ö–ò–ï (–°–¢–ò–õ–ò–°–¢–ò–ß–ï–°–ö–ò–ï) –°–ê–ú–ú–ê–†–ò =====


def _build_author_quarter_prompt(
    channel: str, year: int, quarter: int, texts: list[str]
) -> tuple[str, int, int, int]:
    """
    –°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–≤—Ç–æ—Ä—Å–∫–æ–≥–æ –∫–≤–∞—Ä—Ç–∞–ª—å–Ω–æ–≥–æ —Å–∞–º–º–∞—Ä–∏ —Å —É–º–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–π —Å–æ–æ–±—â–µ–Ω–∏–π.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (prompt, original_count, selected_count, context_chars)
    """
    original_count = len(texts)
    selected_texts = _smart_select_messages(texts, max_chars=9600)  # +20% –ª–∏–º–∏—Ç
    selected_count = len(selected_texts)
    joined = "\n\n".join(selected_texts)
    context_chars = len(joined)
    
    prompt = AUTHOR_QUARTER_PROMPT.format(
        channel=channel, year=year, quarter=quarter, messages=joined
    )
    return prompt, original_count, selected_count, context_chars


def _build_author_year_prompt(
    channel: str, year: int, quarter_summaries: list[str]
) -> tuple[str, int, int, int]:
    """
    –°—Ç—Ä–æ–∏—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∞–≤—Ç–æ—Ä—Å–∫–æ–≥–æ –≥–æ–¥–æ–≤–æ–≥–æ —Å–∞–º–º–∞—Ä–∏ —Å —É–º–Ω–æ–π –≤—ã–±–æ—Ä–∫–æ–π.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (prompt, original_count, selected_count, context_chars)
    """
    original_count = len(quarter_summaries)
    selected_texts = _smart_select_messages(quarter_summaries, max_chars=9600)  # +20% –ª–∏–º–∏—Ç
    selected_count = len(selected_texts)
    joined = "\n\n".join(selected_texts)
    context_chars = len(joined)
    
    prompt = AUTHOR_YEAR_PROMPT.format(
        channel=channel, year=year, quarter_summaries=joined
    )
    return prompt, original_count, selected_count, context_chars


def build_author_quarter_summaries(channel: str) -> list[QuarterSummary]:
    df = _load_raw_channel_df(channel)
    groups = _group_messages_by_year_quarter(df)
    llm = _get_summary_llm()

    summaries: list[QuarterSummary] = []
    total_start = time.time()
    
    logger.info(f"[SUMMARY] –ù–∞—á–∞–ª–æ —Å–æ–∑–¥–∞–Ω–∏—è –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã—Ö —Å–∞–º–º–∞—Ä–∏ –¥–ª—è {channel}")
    
    for (year, quarter), g in sorted(groups.items()):
        texts = [str(t).strip() for t in g["text"].tolist() if str(t).strip()]
        if not texts:
            continue
        
        start_time = time.time()
        prompt, orig_count, sel_count, ctx_chars = _build_author_quarter_prompt(channel, year, quarter, texts)
        
        logger.info(f"[SUMMARY] {channel} {year}Q{quarter} (author): {orig_count}‚Üí{sel_count} msg, {ctx_chars:,} chars")
        
        summary = llm.generate(prompt)
        elapsed = time.time() - start_time
        
        logger.info(f"[SUMMARY] {channel} {year}Q{quarter} (author): –≥–æ—Ç–æ–≤–æ –∑–∞ {elapsed:.1f}s")
        
        summaries.append(
            QuarterSummary(
                channel=channel,
                year=year,
                quarter=quarter,
                summary_text=summary,
            )
        )
    
    total_elapsed = time.time() - total_start
    logger.info(f"[SUMMARY] –í—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ {len(summaries)} –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã—Ö —Å–∞–º–º–∞—Ä–∏ –∑–∞ {total_elapsed:.1f}s")
    
    return summaries


def save_author_quarter_summaries_parquet(
    channel: str, summaries: list[QuarterSummary]
) -> Path:
    if not summaries:
        raise ValueError("No author quarter summaries to save")

    rows = [
        {
            "channel": s.channel,
            "year": s.year,
            "quarter": s.quarter,
            "summary_text": s.summary_text,
        }
        for s in summaries
    ]
    df = pd.DataFrame(rows)
    safe = channel.lstrip("@").replace("/", "_")
    out_dir = Path("data") / "processed" / safe
    out_dir.mkdir(parents=True, exist_ok=True)
    path = out_dir / "summaries_quarter_author.parquet"
    df.to_parquet(path, index=False)
    print(f"üíæ saved author quarter summaries to {path}")
    return path


def save_author_year_summaries_parquet_from_quarters(channel: str) -> Path:
    safe = channel.lstrip("@").replace("/", "_")
    q_path = Path("data") / "processed" / safe / "summaries_quarter_author.parquet"
    if not q_path.exists():
        raise FileNotFoundError(f"author quarter parquet not found: {q_path}")

    df_q = pd.read_parquet(q_path)
    llm = _get_summary_llm()
    rows: list[dict] = []

    total_start = time.time()
    logger.info(f"[SUMMARY] –ù–∞—á–∞–ª–æ —Å–æ–∑–¥–∞–Ω–∏—è –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –≥–æ–¥–æ–≤—ã—Ö —Å–∞–º–º–∞—Ä–∏ –¥–ª—è {channel}")
    
    for year, g in df_q.groupby("year"):
        quarter_summaries = [
            str(t).strip()
            for t in g.sort_values("quarter")["summary_text"].tolist()
            if str(t).strip()
        ]
        if not quarter_summaries:
            continue
        
        start_time = time.time()
        prompt, orig_count, sel_count, ctx_chars = _build_author_year_prompt(channel, int(year), quarter_summaries)
        
        logger.info(f"[SUMMARY] {channel} {year} (author year): {orig_count}‚Üí{sel_count} q-summaries, {ctx_chars:,} chars")
        
        summary = llm.generate(prompt)
        elapsed = time.time() - start_time
        
        logger.info(f"[SUMMARY] {channel} {year} (author year): –≥–æ—Ç–æ–≤–æ –∑–∞ {elapsed:.1f}s")
        rows.append(
            {
                "channel": channel,
                "year": int(year),
                "summary_text": summary,
            }
        )

    df_y = pd.DataFrame(rows)
    out_dir = Path("data") / "processed" / safe
    out_dir.mkdir(parents=True, exist_ok=True)
    path = out_dir / "summaries_year_author.parquet"
    df_y.to_parquet(path, index=False)
    
    total_elapsed = time.time() - total_start
    logger.info(f"[SUMMARY] –í—Å–µ–≥–æ —Å–æ–∑–¥–∞–Ω–æ {len(rows)} –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –≥–æ–¥–æ–≤—ã—Ö —Å–∞–º–º–∞—Ä–∏ –∑–∞ {total_elapsed:.1f}s")
    print(f"üíæ saved author year summaries to {path}")
    return path


def load_author_year_summaries(channel: str) -> Dict[int, str]:
    safe = channel.lstrip("@").replace("/", "_")
    path = Path("data") / "processed" / safe / "summaries_year_author.parquet"
    if not path.exists():
        return {}
    df = pd.read_parquet(path)
    out: Dict[int, str] = {}
    for row in df.itertuples():
        out[int(row.year)] = str(row.summary_text)
    return out


def load_author_quarter_summaries(
    channel: str,
) -> Dict[Tuple[int, int], str]:
    safe = channel.lstrip("@").replace("/", "_")
    path = Path("data") / "processed" / safe / "summaries_quarter_author.parquet"
    if not path.exists():
        return {}
    df = pd.read_parquet(path)
    out: Dict[Tuple[int, int], str] = {}
    for row in df.itertuples():
        out[(int(row.year), int(row.quarter))] = str(row.summary_text)
    return out


def build_author_report(channel: str) -> str:
    part1 = build_author_report_identity_style(channel)
    part2 = build_author_report_evolution_strengths(channel)
    return part1 + "\n\n---\n\n" + part2


def save_author_report(channel: str, report: str) -> Path:
    safe = channel.lstrip("@").replace("/", "_")
    out_dir = Path("data") / "processed" / safe
    out_dir.mkdir(parents=True, exist_ok=True)
    path = out_dir / "author_report.md"
    with open(path, "w", encoding="utf-8") as f:
        f.write(report)
    print(f"üíæ saved author report to {path}")
    return path


def build_author_report_identity_style(channel: str) -> str:
    year_summ = load_year_summaries(channel)
    author_year = load_author_year_summaries(channel)
    author_quarter = load_author_quarter_summaries(channel)

    if not (year_summ or author_year or author_quarter):
        raise RuntimeError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è author_identity_style")

    parts: list[str] = []

    years = sorted(
        set(year_summ.keys())
        | set(author_year.keys())
        | {y for (y, _) in author_quarter.keys()},
        reverse=True,
    )

    for year in years:
        if year in author_year:
            parts.append(
                f"[–°—Ç–∏–ª—å] –ì–æ–¥ {year}:\n{author_year[year].strip()}"
            )

    for (y, q), txt in author_quarter.items():
        if y in years and txt.strip():
            parts.append(f"[–°—Ç–∏–ª—å] {y} Q{q}:\n{txt.strip()}")

    raw = "\n\n".join(parts)
    max_chars = 6000
    if len(raw) > max_chars:
        raw = raw[:max_chars]

    prompt = AUTHOR_REPORT_IDENTITY_STYLE_PROMPT.format(
        channel=channel, summaries=raw
    )
    llm = _get_summary_llm()
    return llm.generate(prompt).strip()


def build_author_report_evolution_strengths(channel: str) -> str:
    year_summ = load_year_summaries(channel)
    author_year = load_author_year_summaries(channel)

    if not (year_summ or author_year):
        raise RuntimeError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è author_evolution_strengths")

    parts: list[str] = []
    years = sorted(set(year_summ.keys()) | set(author_year.keys()), reverse=True)

    for year in years:
        if year in year_summ:
            parts.append(f"[–†—ã–Ω–æ–∫] {year}:\n{year_summ[year].strip()}")
        if year in author_year:
            parts.append(f"[–°—Ç–∏–ª—å] {year}:\n{author_year[year].strip()}")

    raw = "\n\n".join(parts)
    max_chars = 10000
    if len(raw) > max_chars:
        raw = raw[:max_chars]

    prompt = AUTHOR_REPORT_EVOLUTION_STRENGTHS_PROMPT.format(
        channel=channel, summaries=raw
    )
    llm = _get_summary_llm()
    return llm.generate(prompt).strip()


def _build_year_evolution_paragraph(channel: str, year: int) -> str:
    year_summ_all = load_year_summaries(channel)
    author_year_all = load_author_year_summaries(channel)

    year_summ = year_summ_all.get(year)
    author_year = author_year_all.get(year)

    if not (year_summ or author_year):
        return ""

    parts = []
    if year_summ:
        parts.append(f"[–†—ã–Ω–æ–∫] {year}:\n{year_summ.strip()}")
    if author_year:
        parts.append(f"[–°—Ç–∏–ª—å] {year}:\n{author_year.strip()}")

    raw = "\n\n".join(parts)
    max_chars = 2000
    if len(raw) > max_chars:
        raw = raw[:max_chars]

    prompt = YEAR_EVOLUTION_PARAGRAPH_PROMPT.format(
        channel=channel, year=year, summaries=raw
    )
    llm = _get_summary_llm()
    return llm.generate(prompt).strip()


def build_author_report_evolution_strengths_full(channel: str) -> str:
    year_summ = load_year_summaries(channel)
    author_year = load_author_year_summaries(channel)

    if not (year_summ or author_year):
        raise RuntimeError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è author_evolution_strengths")

    years = sorted(set(year_summ.keys()) | set(author_year.keys()))
    evolution_blocks: list[str] = []

    for year in years:
        para = _build_year_evolution_paragraph(channel, year)
        if para:
            evolution_blocks.append(f"- **{year}:** {para}")

    evolution_text = "\n".join(evolution_blocks)

    raw = evolution_text
    max_chars = 4000
    if len(raw) > max_chars:
        raw = raw[:max_chars]

    prompt = AUTHOR_REPORT_EVOLUTION_STRENGTHS_PROMPT.format(
        channel=channel, summaries=raw
    )
    llm = _get_summary_llm()
    summary = llm.generate(prompt).strip()
    return evolution_text + "\n\n" + summary


# ===== –ù–û–í–´–ï –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–ò –î–õ–Ø –ü–ê–†–ê–õ–õ–ï–õ–ò–ó–ú–ê =====


def _summarize_quarter_market(
    channel: str, year: int, quarter: int, texts: list[str]
) -> QuarterSummary:
    llm = _get_summary_llm()
    start_time = time.time()
    prompt, orig_count, sel_count, ctx_chars = _build_quarter_prompt(channel, year, quarter, texts)
    
    logger.info(f"[SUMMARY] {channel} {year}Q{quarter}: {orig_count}‚Üí{sel_count} msg, {ctx_chars:,} chars")
    
    summary = llm.generate(prompt)
    elapsed = time.time() - start_time
    
    logger.info(f"[SUMMARY] {channel} {year}Q{quarter}: –≥–æ—Ç–æ–≤–æ –∑–∞ {elapsed:.1f}s")
    
    return QuarterSummary(
        channel=channel, year=year, quarter=quarter, summary_text=summary
    )


def _summarize_quarter_author(
    channel: str, year: int, quarter: int, texts: list[str]
) -> QuarterSummary:
    llm = _get_summary_llm()
    start_time = time.time()
    prompt, orig_count, sel_count, ctx_chars = _build_author_quarter_prompt(channel, year, quarter, texts)
    
    logger.info(f"[SUMMARY] {channel} {year}Q{quarter} (author): {orig_count}‚Üí{sel_count} msg, {ctx_chars:,} chars")
    
    summary = llm.generate(prompt)
    elapsed = time.time() - start_time
    
    logger.info(f"[SUMMARY] {channel} {year}Q{quarter} (author): –≥–æ—Ç–æ–≤–æ –∑–∞ {elapsed:.1f}s")
    
    return QuarterSummary(
        channel=channel, year=year, quarter=quarter, summary_text=summary
    )


async def _summarize_quarter_market_async(
    channel: str, year: int, quarter: int, texts: list[str]
) -> QuarterSummary:
    return await _run_in_thread(
        _summarize_quarter_market, channel, year, quarter, texts
    )


async def _summarize_quarter_author_async(
    channel: str, year: int, quarter: int, texts: list[str]
) -> QuarterSummary:
    return await _run_in_thread(
        _summarize_quarter_author, channel, year, quarter, texts
    )


async def _phase_quarters_async(
    channel: str,
) -> Tuple[list[QuarterSummary], list[QuarterSummary]]:
    """
    –§–∞–∑–∞ 1: —Å—á–∏—Ç–∞–µ–º –≤—Å–µ –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ —Å–∞–º–º–∞—Ä–∏ (—Ä—ã–Ω–æ—á–Ω—ã–µ –∏ –∞–≤—Ç–æ—Ä—Å–∫–∏–µ) –≤ 3 –ø–æ—Ç–æ–∫–∞.
    """
    total_start = time.time()
    df = _load_raw_channel_df(channel)
    groups = _group_messages_by_year_quarter(df)

    market_tasks: list[asyncio.Task] = []
    author_tasks: list[asyncio.Task] = []

    for (year, quarter), g in sorted(groups.items()):
        texts = [str(t).strip() for t in g["text"].tolist() if str(t).strip()]
        if not texts:
            continue
        market_tasks.append(
            asyncio.create_task(
                _summarize_quarter_market_async(channel, year, quarter, texts)
            )
        )
        author_tasks.append(
            asyncio.create_task(
                _summarize_quarter_author_async(channel, year, quarter, texts)
            )
        )

    market_summaries: list[QuarterSummary] = []
    author_summaries: list[QuarterSummary] = []

    if market_tasks:
        logger.info(f"[SUMMARY] –ó–∞–ø—É—Å–∫ {len(market_tasks)} —Ä—ã–Ω–æ—á–Ω—ã—Ö –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã—Ö —Å–∞–º–º–∞—Ä–∏...")
        market_summaries = list(await asyncio.gather(*market_tasks))
    if author_tasks:
        logger.info(f"[SUMMARY] –ó–∞–ø—É—Å–∫ {len(author_tasks)} –∞–≤—Ç–æ—Ä—Å–∫–∏—Ö –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã—Ö —Å–∞–º–º–∞—Ä–∏...")
        author_summaries = list(await asyncio.gather(*author_tasks))

    total_elapsed = time.time() - total_start
    logger.info(f"[SUMMARY] –ö–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ —Å–∞–º–º–∞—Ä–∏: {len(market_summaries)} market + {len(author_summaries)} author –∑–∞ {total_elapsed:.1f}s")

    return market_summaries, author_summaries


async def _phase_years_and_report_async(channel: str) -> None:
    """
    –§–∞–∑–∞ 2: –ø–æ—Å–ª–µ —Ç–æ–≥–æ, –∫–∞–∫ –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ parquet —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.
    –°—á–∏—Ç–∞–µ–º –≥–æ–¥–æ–≤—ã–µ (—Ä—ã–Ω–æ—á–Ω—ã–µ –∏ –∞–≤—Ç–æ—Ä—Å–∫–∏–µ) –∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç.
    """

    def _build_years_sync() -> list[PeriodSummary]:
        return build_year_summaries(channel)

    year_summ = await _run_in_thread(_build_years_sync)
    if year_summ:
        save_year_summaries_parquet(channel, year_summ)

    await _run_in_thread(save_author_year_summaries_parquet_from_quarters, channel)

    def _build_report_sync() -> str:
        return build_author_report(channel)

    report = await _run_in_thread(_build_report_sync)
    save_author_report(channel, report)


async def build_all_summaries_and_report_async(channel: str) -> None:
    """
    –î–≤—É—Ö—Ñ–∞–∑–Ω—ã–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω:
    1) –≤—Å–µ –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ (market + author) –≤ 3 –ø–æ—Ç–æ–∫–∞;
    2) –ø–æ—Å–ª–µ —ç—Ç–æ–≥–æ –≥–æ–¥–æ–≤—ã–µ + author_year + —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç.
    """
    steps = 5
    step = 1

    print(
        f"[{step}/{steps}] –ö–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ (—Ä—ã–Ω–æ—á–Ω—ã–µ + –∞–≤—Ç–æ—Ä—Å–∫–∏–µ) —Å–∞–º–º–∞—Ä–∏..."
    )
    market_quarters, author_quarters = await _phase_quarters_async(channel)

    if market_quarters:
        save_quarter_summaries_parquet(channel, market_quarters)
    if author_quarters:
        save_author_quarter_summaries_parquet(channel, author_quarters)

    step = 4
    print(f"[{step}/{steps}] –ê–≤—Ç–æ—Ä—Å–∫–∏–µ –≥–æ–¥–æ–≤—ã–µ —Å–∞–º–º–∞—Ä–∏ –∏ –æ—Ç—á—ë—Ç...")
    await _phase_years_and_report_async(channel)

    print("‚úÖ tg-build-summaries (async): –≤—Å–µ —Å–∞–º–º–∞—Ä–∏ –∏ –æ—Ç—á—ë—Ç –≥–æ—Ç–æ–≤—ã.")
