import argparse
import sys
import time
import asyncio
import logging
import os

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–æ–¥–∏—Ä–æ–≤–∫–∏ UTF-8 –¥–ª—è Windows
if sys.platform == "win32":
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except AttributeError:
        # –î–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π Python
        os.environ['PYTHONIOENCODING'] = 'utf-8'

sys.path.insert(0, '.')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è —Å–∞–º–º–∞—Ä–∏
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%H:%M:%S'
)

from vectorstore.chromadb_store import ChromaStore
from rag.pipeline import RAGPipeline

from telethon import TelegramClient
from telethon.tl.types import Message
import pandas as pd

from config_telegram import raw_parquet_path, TG_API_ID, TG_API_HASH, TG_SESSION_NAME
from tg_channels.schema import TgMessage

from tg_channels.ingest import ingest_tg_channel

from tg_channels.summaries import load_year_summaries, load_quarter_summaries
from tg_channels.summaries import build_all_summaries_and_report_async

from typing import List
from settings import MAX_MSGS, LOG_STEP


async def _fetch_channel_messages(channel: str) -> List[TgMessage]:
    if not TG_API_ID or not TG_API_HASH:
        raise RuntimeError("–ó–∞–ø–æ–ª–Ω–∏ TG_API_ID –∏ TG_API_HASH –≤ config_telegram.py")

    from config_telegram import normalize_channel_name
    
    client = TelegramClient(TG_SESSION_NAME, TG_API_ID, TG_API_HASH)
    chan = normalize_channel_name(channel)

    messages: List[TgMessage] = []
    BATCH_SIZE = 1000  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ –ø–∞–º—è—Ç–∏

    async with client:
        # –Ω–æ–≤—ã–µ ‚Üí —Å—Ç–∞—Ä—ã–µ
        async for msg in client.iter_messages(chan):
            if not isinstance(msg, Message):
                continue

            text = msg.message or ""
            if not text and not msg.media:
                continue

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–µ—Å—ã–ª–∫—É
            is_forwarded = False
            forwarded_from_channel = None
            forwarded_from_msg_id = None
            
            if hasattr(msg, 'fwd_from') and msg.fwd_from:
                is_forwarded = True
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ –ø–µ—Ä–µ—Å—ã–ª–∫–∏
                if hasattr(msg.fwd_from, 'from_id'):
                    from_id = msg.fwd_from.from_id
                    # from_id –º–æ–∂–µ—Ç –±—ã—Ç—å PeerChannel, PeerUser –∏ —Ç.–¥.
                    if hasattr(from_id, 'channel_id'):
                        # –≠—Ç–æ –∫–∞–Ω–∞–ª, –Ω–æ –Ω–∞–º –Ω—É–∂–µ–Ω username
                        # –í telethon –æ–±—ã—á–Ω–æ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è username
                        # –ü–æ–∫–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ ID
                        forwarded_from_channel = f"channel_{from_id.channel_id}"
                    elif hasattr(from_id, 'user_id'):
                        forwarded_from_channel = f"user_{from_id.user_id}"
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π msg_id
                if hasattr(msg.fwd_from, 'channel_post'):
                    forwarded_from_msg_id = msg.fwd_from.channel_post

            m = TgMessage(
                channel=chan,
                msg_id=msg.id,
                date=msg.date,
                edit_date=msg.edit_date,
                sender_id=getattr(msg.sender, "id", None),
                text=text,
                views=msg.views,
                forwards=msg.forwards,
                reply_to_msg_id=getattr(
                    getattr(msg, "reply_to", None), "reply_to_msg_id", None
                ),
                has_media=msg.media is not None,
                is_forwarded=is_forwarded,
                forwarded_from_channel=forwarded_from_channel,
                forwarded_from_msg_id=forwarded_from_msg_id,
            )
            messages.append(m)

            n = len(messages)
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            if n % LOG_STEP == 0:
                print(f"[tg-sync] {chan}: —Å–∫–∞—á–∞–Ω–æ {n} —Å–æ–æ–±—â–µ–Ω–∏–π")
            
            # –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –≤ –ø–∞–º—è—Ç–∏
            # –ù–∞ –ø—Ä–∞–∫—Ç–∏–∫–µ —ç—Ç–æ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, —Ç–∞–∫ –∫–∞–∫ –º—ã –≤—Å–µ —Ä–∞–≤–Ω–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–µ—Å—å —Å–ø–∏—Å–æ–∫
            # –ù–æ —ç—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
            if n >= MAX_MSGS:
                print(f"[tg-sync] {chan}: –¥–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç {MAX_MSGS} —Å–æ–æ–±—â–µ–Ω–∏–π, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è")
                break

    return messages

def cmd_tg_sync(args):
    """
    –ü–æ–ª–Ω–∞—è –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–∞—è –≤—ã–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ –∫–∞–Ω–∞–ª–∞ –≤ data/raw/<channel>.parquet
    –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏.
    """
    from config_telegram import normalize_channel_name
    
    channel = normalize_channel_name(args.channel)
    if not channel:
        print(f"–û—à–∏–±–∫–∞: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –∫–∞–Ω–∞–ª–∞: {args.channel}")
        return
    print(f"‚ñ∂ tg-sync: fetching history for {channel}")

    msgs: List[TgMessage] = asyncio.run(_fetch_channel_messages(channel))
    print(f"‚úÖ fetched {len(msgs)} messages")

    if not msgs:
        return

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º ID –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è (—Å–∞–º–æ–µ –Ω–æ–≤–æ–µ, —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º msg_id)
    last_msg_id = max(m.msg_id for m in msgs) if msgs else None

    # –ë–∞—Ç—á–µ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –±–∞—Ç—á–∞–º–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
    BATCH_SIZE = 5000
    path = raw_parquet_path(channel)
    
    # –ï—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–µ–º–Ω–æ–≥–æ, —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ä–∞–∑—É
    if len(msgs) <= BATCH_SIZE:
        df = pd.DataFrame(
            [
                {
                    "channel": m.channel,
                    "msg_id": m.msg_id,
                    "date": m.date,
                    "edit_date": m.edit_date,
                    "sender_id": m.sender_id,
                    "text": m.text,
                    "views": m.views,
                    "forwards": m.forwards,
                    "reply_to_msg_id": m.reply_to_msg_id,
                    "has_media": m.has_media,
                    "is_forwarded": m.is_forwarded,
                    "forwarded_from_channel": m.forwarded_from_channel,
                    "forwarded_from_msg_id": m.forwarded_from_msg_id,
                }
                for m in msgs
            ]
        )
        df.to_parquet(path, index=False)
        print(f"üíæ saved to {path}")
    else:
        # –î–ª—è –±–æ–ª—å—à–∏—Ö –æ–±—ä–µ–º–æ–≤: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º
        dfs = []
        for i in range(0, len(msgs), BATCH_SIZE):
            batch = msgs[i:i + BATCH_SIZE]
            batch_df = pd.DataFrame(
                [
                    {
                        "channel": m.channel,
                        "msg_id": m.msg_id,
                        "date": m.date,
                        "edit_date": m.edit_date,
                        "sender_id": m.sender_id,
                        "text": m.text,
                        "views": m.views,
                        "forwards": m.forwards,
                        "reply_to_msg_id": m.reply_to_msg_id,
                        "has_media": m.has_media,
                        "is_forwarded": m.is_forwarded,
                        "forwarded_from_channel": m.forwarded_from_channel,
                        "forwarded_from_msg_id": m.forwarded_from_msg_id,
                    }
                    for m in batch
                ]
            )
            dfs.append(batch_df)
            print(f"[tg-sync] –û–±—Ä–∞–±–æ—Ç–∞–Ω –±–∞—Ç—á {i//BATCH_SIZE + 1} ({len(batch)} —Å–æ–æ–±—â–µ–Ω–∏–π)")
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –±–∞—Ç—á–∏
        df = pd.concat(dfs, ignore_index=True)
        df.to_parquet(path, index=False)
        print(f"üíæ saved {len(msgs)} messages to {path}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º last_synced_msg_id –≤ –ë–î
    if last_msg_id:
        from tgbot.bot_db import set_last_synced_msg_id
        set_last_synced_msg_id(channel, last_msg_id)
        print(f"üíæ saved last_synced_msg_id: {last_msg_id}")



async def _fetch_channel_messages_incremental(channel: str, last_msg_id: int | None = None) -> List[TgMessage]:
    """
    –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∫–∞–Ω–∞–ª–∞.
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Å msg_id > last_msg_id.
    """
    if not TG_API_ID or not TG_API_HASH:
        raise RuntimeError("–ó–∞–ø–æ–ª–Ω–∏ TG_API_ID –∏ TG_API_HASH –≤ config_telegram.py")

    from config_telegram import normalize_channel_name
    
    client = TelegramClient(TG_SESSION_NAME, TG_API_ID, TG_API_HASH)
    chan = normalize_channel_name(channel)

    messages: List[TgMessage] = []

    async with client:
        # –Ω–æ–≤—ã–µ ‚Üí —Å—Ç–∞—Ä—ã–µ
        async for msg in client.iter_messages(chan):
            if not isinstance(msg, Message):
                continue
            
            # –ï—Å–ª–∏ –µ—Å—Ç—å last_msg_id, –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º—Å—è –∫–æ–≥–¥–∞ –¥–æ—Å—Ç–∏–≥–ª–∏ –µ–≥–æ
            if last_msg_id is not None and msg.id <= last_msg_id:
                break

            text = msg.message or ""
            if not text and not msg.media:
                continue

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–µ—Ä–µ—Å—ã–ª–∫—É
            is_forwarded = False
            forwarded_from_channel = None
            forwarded_from_msg_id = None
            
            if hasattr(msg, 'fwd_from') and msg.fwd_from:
                is_forwarded = True
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å—Ç–æ—á–Ω–∏–∫–µ –ø–µ—Ä–µ—Å—ã–ª–∫–∏
                if hasattr(msg.fwd_from, 'from_id'):
                    from_id = msg.fwd_from.from_id
                    # from_id –º–æ–∂–µ—Ç –±—ã—Ç—å PeerChannel, PeerUser –∏ —Ç.–¥.
                    if hasattr(from_id, 'channel_id'):
                        # –≠—Ç–æ –∫–∞–Ω–∞–ª, –Ω–æ –Ω–∞–º –Ω—É–∂–µ–Ω username
                        # –í telethon –æ–±—ã—á–Ω–æ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è username
                        # –ü–æ–∫–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ ID
                        forwarded_from_channel = f"channel_{from_id.channel_id}"
                    elif hasattr(from_id, 'user_id'):
                        forwarded_from_channel = f"user_{from_id.user_id}"
                
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π msg_id
                if hasattr(msg.fwd_from, 'channel_post'):
                    forwarded_from_msg_id = msg.fwd_from.channel_post

            m = TgMessage(
                channel=chan,
                msg_id=msg.id,
                date=msg.date,
                edit_date=msg.edit_date,
                sender_id=getattr(msg.sender, "id", None),
                text=text,
                views=msg.views,
                forwards=msg.forwards,
                reply_to_msg_id=getattr(
                    getattr(msg, "reply_to", None), "reply_to_msg_id", None
                ),
                has_media=msg.media is not None,
                is_forwarded=is_forwarded,
                forwarded_from_channel=forwarded_from_channel,
                forwarded_from_msg_id=forwarded_from_msg_id,
            )
            messages.append(m)

            n = len(messages)
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            if n % LOG_STEP == 0:
                print(f"[tg-update] {chan}: —Å–∫–∞—á–∞–Ω–æ {n} –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")

    return messages


def cmd_tg_update(args):
    """
    –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –∫–∞–Ω–∞–ª–∞.
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å –º–æ–º–µ–Ω—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω–µ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏.
    """
    from config_telegram import normalize_channel_name, raw_parquet_path
    from tgbot.bot_db import get_last_synced_msg_id, set_last_synced_msg_id
    
    channel = normalize_channel_name(args.channel)
    if not channel:
        print(f"–û—à–∏–±–∫–∞: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –∫–∞–Ω–∞–ª–∞: {args.channel}")
        return
    
    # –ü–æ–ª—É—á–∞–µ–º ID –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
    last_msg_id = get_last_synced_msg_id(channel)
    
    if last_msg_id is None:
        print(f"‚ö†Ô∏è  –ö–∞–Ω–∞–ª {channel} –µ—â–µ –Ω–µ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ 'tg-sync' –¥–ª—è –ø–µ—Ä–≤–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏.")
        return
    
    print(f"‚ñ∂ tg-update: fetching new messages for {channel} (–ø–æ—Å–ª–µ msg_id={last_msg_id})")
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    new_msgs: List[TgMessage] = asyncio.run(_fetch_channel_messages_incremental(channel, last_msg_id))
    print(f"‚úÖ fetched {len(new_msgs)} –Ω–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")

    if not new_msgs:
        print("‚ÑπÔ∏è  –ù–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –Ω–µ—Ç.")
        return

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–∞–Ω–Ω—ã–µ
    path = raw_parquet_path(channel)
    if path.exists():
        existing_df = pd.read_parquet(path)
        print(f"üìÇ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(existing_df)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")
    else:
        existing_df = pd.DataFrame()
        print("üìÇ –°—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Ñ–∞–π–ª")

    # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
    new_df = pd.DataFrame(
        [
            {
                "channel": m.channel,
                "msg_id": m.msg_id,
                "date": m.date,
                "edit_date": m.edit_date,
                "sender_id": m.sender_id,
                "text": m.text,
                "views": m.views,
                "forwards": m.forwards,
                "reply_to_msg_id": m.reply_to_msg_id,
                "has_media": m.has_media,
                "is_forwarded": m.is_forwarded,
                "forwarded_from_channel": m.forwarded_from_channel,
                "forwarded_from_msg_id": m.forwarded_from_msg_id,
            }
            for m in new_msgs
        ]
    )
    
    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ —É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã (–Ω–∞ —Å–ª—É—á–∞–π –µ—Å–ª–∏ msg_id —É–∂–µ –µ—Å—Ç—å)
    combined_df = pd.concat([existing_df, new_df], ignore_index=True)
    combined_df = combined_df.drop_duplicates(subset=["msg_id"], keep="last")
    combined_df = combined_df.sort_values("msg_id", ascending=False)  # –Ω–æ–≤—ã–µ —Å–≤–µ—Ä—Ö—É
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º
    combined_df.to_parquet(path, index=False)
    print(f"üíæ saved {len(combined_df)} total messages to {path}")
    
    # –û–±–Ω–æ–≤–ª—è–µ–º last_synced_msg_id
    if new_msgs:
        new_last_msg_id = max(m.msg_id for m in new_msgs)
        set_last_synced_msg_id(channel, new_last_msg_id)
        print(f"üíæ updated last_synced_msg_id: {new_last_msg_id}")


def cmd_tg_ingest(args):
    from config_telegram import normalize_channel_name
    
    channel = normalize_channel_name(args.channel)
    if not channel:
        print(f"–û—à–∏–±–∫–∞: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –∫–∞–Ω–∞–ª–∞: {args.channel}")
        return
    print(f"‚ñ∂ tg-ingest: {channel}")
    ingest_tg_channel(channel)


def cmd_tg_reindex(args):
    """–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä—É–µ—Ç –∫–∞–Ω–∞–ª –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ –ë–î –∏ —Ñ–∞–π–ª–æ–≤."""
    from config_telegram import normalize_channel_name
    from tg_channels.ingest import reindex_tg_channel
    
    channel = normalize_channel_name(args.channel)
    if not channel:
        print(f"–û—à–∏–±–∫–∞: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –∫–∞–Ω–∞–ª–∞: {args.channel}")
        return
    print(f"‚ñ∂ tg-reindex: {channel} (–¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î –∏ —Ñ–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è)")
    reindex_tg_channel(channel)


def cmd_tg_delete(args):
    """–£–¥–∞–ª—è–µ—Ç –∫–∞–Ω–∞–ª –∏–∑ –ë–î, ChromaDB –∏ —Ñ–∞–π–ª–æ–≤."""
    from config_telegram import normalize_channel_name
    from tgbot.bot_tasks import delete_channel_completely
    
    channel = normalize_channel_name(args.channel)
    if not channel:
        print(f"–û—à–∏–±–∫–∞: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –∫–∞–Ω–∞–ª–∞: {args.channel}")
        return
    
    print(f">> tg-delete: {channel}")
    print(f"[!] –í–Ω–∏–º–∞–Ω–∏–µ: –æ–ø–µ—Ä–∞—Ü–∏—è –Ω–µ–æ–±—Ä–∞—Ç–∏–º–∞!")
    
    result = delete_channel_completely(channel)
    
    if result.get("success"):
        stats = result.get("chromadb_stats", {})
        print(f"[OK] {result.get('message', '–ö–∞–Ω–∞–ª —É–¥–∞–ª–µ–Ω')}")
        print(f"   –ß–∞–Ω–∫–æ–≤ —É–¥–∞–ª–µ–Ω–æ: {stats.get('chunks_deleted', 0)}")
        print(f"   –°–∞–º–º–∞—Ä–∏ —É–¥–∞–ª–µ–Ω–æ: {stats.get('summaries_deleted', 0)}")
        print(f"   –§–∞–π–ª—ã: {'[OK]' if result.get('files_deleted') else '[NOT FOUND]'}")
    else:
        print(f"[ERROR] {result.get('message', '–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏')}")
        if result.get("errors"):
            print(f"   –û—à–∏–±–∫–∏: {', '.join(result['errors'])}")


def cmd_tg_query(args):
    from config_telegram import normalize_channel_name
    
    channel = normalize_channel_name(args.channel)
    if not channel:
        print(f"–û—à–∏–±–∫–∞: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –∫–∞–Ω–∞–ª–∞: {args.channel}")
        return
    question = args.question

    print(f"‚ñ∂ tg-query: channel={channel}, q={question!r}")
    rag = RAGPipeline(backend=args.backend)

    # –≥—Ä—É–∑–∏–º –≥–æ–¥–æ–≤—ã–µ –∏ –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ —Å–∞–º–º–∞—Ä–∏
    year_summaries = load_year_summaries(channel)
    quarter_summaries = load_quarter_summaries(channel)

    start = time.time()
    ans = rag.query(
        question,
        source="telegram",
        channel=channel,
        extra_year_summaries=year_summaries,
        extra_quarter_summaries=quarter_summaries,
    )

    print(f"Total time: {time.time() - start:.1f}s")
    print(f"–ö–∞–Ω–∞–ª: {channel}")
    print(f"–í–æ–ø—Ä–æ—Å: {question}")
    print(f"–û—Ç–≤–µ—Ç:\n{ans}")

# ====== –ï–î–ò–ù–´–ô CLI –° SUBCOMMANDS ======

def build_cli():
    parser = argparse.ArgumentParser()
    sub = parser.add_subparsers(dest="command", required=True)

    # ---- tg-* –∫–æ–º–∞–Ω–¥—ã ----
    p_tg_sync = sub.add_parser("tg-sync", help="download Telegram channel history")
    p_tg_sync.add_argument("channel", help="@channelname")
    p_tg_sync.set_defaults(func=cmd_tg_sync)

    p_tg_update = sub.add_parser("tg-update", help="update Telegram channel history")
    p_tg_update.add_argument("channel", help="@channelname")
    p_tg_update.set_defaults(func=cmd_tg_update)

    p_tg_ingest = sub.add_parser("tg-ingest", help="ingest Telegram channel into vector index")
    p_tg_ingest.add_argument("channel", help="@channelname")
    p_tg_ingest.set_defaults(func=cmd_tg_ingest)

    p_tg_reindex = sub.add_parser("tg-reindex", help="reindex Telegram channel (keeps DB and files, only updates ChromaDB)")
    p_tg_reindex.add_argument("channel", help="@channelname")
    p_tg_reindex.set_defaults(func=cmd_tg_reindex)

    p_tg_delete = sub.add_parser("tg-delete", help="delete Telegram channel completely (removes from DB, ChromaDB and files)")
    p_tg_delete.add_argument("channel", help="@channelname")
    p_tg_delete.set_defaults(func=cmd_tg_delete)

    p_tg_query = sub.add_parser("tg-query", help="query Telegram channel archive")
    p_tg_query.add_argument("channel", help="@channelname")
    p_tg_query.add_argument("question", help="–í–æ–ø—Ä–æ—Å –∫ –∞—Ä—Ö–∏–≤–∞—Ä–∏—É—Å—É –∫–∞–Ω–∞–ª–∞")
    p_tg_query.add_argument(
        "--backend",
        choices=["local", "deepseek", "openai"],
        default="deepseek",
        help="LLM backend for query",
    )
    p_tg_query.set_defaults(func=cmd_tg_query)

    p_tg_build_sum = sub.add_parser("tg-build-summaries", help="build yearly summaries for Telegram channel")
    p_tg_build_sum.add_argument("channel", help="@channelname")
    p_tg_build_sum.set_defaults(func=cmd_tg_build_summaries)

    # ---- –ù–û–í–´–ï –∫–æ–º–∞–Ω–¥—ã ----
    p_tg_index_summ = sub.add_parser("tg-index-summaries", help="–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Å–∞–º–º–∞—Ä–∏ –≤ Chroma")
    p_tg_index_summ.add_argument("channel", help="@channelname")
    p_tg_index_summ.set_defaults(func=cmd_tg_index_summaries)

    p_status = sub.add_parser("status", help="status of vector index")
    p_status.set_defaults(func=cmd_status)

    return parser


def cmd_tg_build_summaries(args):
    from config_telegram import normalize_channel_name
    
    channel = normalize_channel_name(args.channel)
    if not channel:
        print(f"–û—à–∏–±–∫–∞: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –∫–∞–Ω–∞–ª–∞: {args.channel}")
        return

    print(f"tg-build-summaries: {channel}")
    asyncio.run(build_all_summaries_and_report_async(channel))


def cmd_tg_index_summaries(args):
    from pathlib import Path
    import pandas as pd
    from config_telegram import normalize_channel_name

    channel = normalize_channel_name(args.channel)
    if not channel:
        print(f"–û—à–∏–±–∫–∞: –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∏–º—è –∫–∞–Ω–∞–ª–∞: {args.channel}")
        return
    store = ChromaStore()

    # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ —Å–∞–º–º–∞—Ä–∏ –∏ author_report –¥–ª—è —ç—Ç–æ–≥–æ –∫–∞–Ω–∞–ª–∞ –ø–µ—Ä–µ–¥ –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π
    # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã –ø—Ä–∏ –ø–µ—Ä–µ—Å–±–æ—Ä–∫–µ
    print(f"üóëÔ∏è  –£–¥–∞–ª–µ–Ω–∏–µ —Å—Ç–∞—Ä—ã—Ö —Å–∞–º–º–∞—Ä–∏ –¥–ª—è {channel}...")
    try:
        # –£–¥–∞–ª—è–µ–º —Å–∞–º–º–∞—Ä–∏ (summary)
        store.collection.delete(
            where={
                "$and": [
                    {"channel": channel},
                    {"type": "summary"}
                ]
            }
        )
        # –£–¥–∞–ª—è–µ–º author_report
        store.collection.delete(
            where={
                "$and": [
                    {"channel": channel},
                    {"type": "author_report"}
                ]
            }
        )
        print(f"‚úÖ –°—Ç–∞—Ä—ã–µ —Å–∞–º–º–∞—Ä–∏ —É–¥–∞–ª–µ–Ω—ã")
    except Exception as e:
        print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Å—Ç–∞—Ä—ã—Ö —Å–∞–º–º–∞—Ä–∏: {e}")
        # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—é –¥–∞–∂–µ –µ—Å–ª–∏ —É–¥–∞–ª–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å

    # –ì–æ–¥–æ–≤—ã–µ + –∫–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ (–≤—Å–µ –∏–º–µ—é—Ç summary_text)
    for path_str, doc_id in [
        (f"data/processed/{channel}/summaries_year.parquet", f"{channel}_year_summaries"),
        (f"data/processed/{channel}/summaries_quarter.parquet", f"{channel}_quarter_summaries"),
        (f"data/processed/{channel}/summaries_year_author.parquet", f"{channel}_year_author_summaries"),
        (f"data/processed/{channel}/summaries_quarter_author.parquet", f"{channel}_quarter_author_summaries"),
    ]:
        path = Path(path_str)
        if not path.exists():
            print(f"‚ö†Ô∏è  {path} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
            continue

        df = pd.read_parquet(path)
        chunks = [
            {
                "text": str(row["summary_text"]),  # ‚Üê —Ç–æ—á–Ω–æ summary_text
                "metadata": {
                    "type": "summary",
                    "channel": channel,
                    "doc_id": doc_id,
                    "period": row.get("period", row.get("year", ""))
                }
            }
            for _, row in df.iterrows()
        ]
        store.add_chunks(chunks)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(chunks)} —Å–∞–º–º–∞—Ä–∏ –∏–∑ {path.name}")

    # author_report.md
    report_path = Path(f"data/processed/{channel}/author_report.md")
    if report_path.exists():
        with open(report_path, 'r', encoding='utf-8') as f:
            text = f.read()
        chunks = [{"text": text[:4000], "metadata": {"type": "author_report", "channel": channel}}]
        store.add_chunks(chunks)
        print("‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω author_report.md")

    print(f"‚úÖ –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω—ã —Å–∞–º–º–∞—Ä–∏ –¥–ª—è {channel}. Total: {store.count()}")


def cmd_status(args):
    store = ChromaStore()
    print(f"Total chunks: {store.count()}")
    # –ü—Ä–µ–≤—å—é –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 3 —á–∞–Ω–∫–æ–≤
    results = store.collection.peek(limit=3)
    if results['metadatas']:
        for i, meta in enumerate(results['metadatas']):
            print(f"  {i+1}. {meta.get('channel', '?')} | {meta.get('type', 'chunk')}")


if __name__ == "__main__":
    parser = build_cli()
    args = parser.parse_args()
    args.func(args)
